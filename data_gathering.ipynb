{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 - Problem Definition\n",
    "###    1.1 Official Goal(s):\n",
    "        For project 3, your goal is two-fold:\n",
    "        1. Using [Pushshift's](https://github.com/pushshift/api) API, you'll collect posts from two subreddits of your choosing.\n",
    "        2. You'll then use NLP to train a classifier on which subreddit a given post came from. This is a binary classification problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Subreddit Selection\n",
    "\n",
    "Reddit.com has a 'best of' feature-- both of Reddit itself and of specific subreddits.  How a post or comment is selected to be a 'best of' is a fascinating rabbit hole to dig in to- see a guest post by Randall Munroe of XKCD fame on the subject here: \n",
    "    https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system/\n",
    "    or take a look at the reddit post asking the same question here:\n",
    "    https://www.reddit.com/r/NoStupidQuestions/comments/6cmz29/how_does_reddit_determine_the_best_ranking_in_a/\n",
    "\n",
    "TL;DR- it combines a statistical algorithm that tracks the activity, number of comments and number of upvotes to determine which comments and which posts are the most engaged with and flags it for a redditor's review.\n",
    "\n",
    "The question I wanted to examine is whether or not the titles can be parsed to determine whether they come from the original subreddit or from the 'best of' subreddit *in the same category.*\n",
    "    \n",
    "To do this I'm looking at the subreddits of:\n",
    "\n",
    "    1. r/legaladvice\n",
    "    2. r/bestoflegaladvice\n",
    "\n",
    "In short: can we build a model that will predict whether a post is from the legal advice subreddit or the curated best of legal advice subreddit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Problem Statement\n",
    "\n",
    "How well can we train a classification model to correctly classify the title of a subreddit post as belonging to the r/legaladvice subreddit or the r/bestoflegaladvice subreddt?\n",
    "\n",
    "Stretch question:  Predict which r/legaladvice posts are most likely to be added to r/bestoflegaladvice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - Data Gathering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 define function(s) to gather posts from reddit using pushshift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts(subreddit, n):\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "    if n < 100:\n",
    "        params = {\n",
    "        'subreddit' : subreddit, \n",
    "        'size': n \n",
    "        }\n",
    "        res = requests.get(url, params)\n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "    else:\n",
    "# note:  Pushshift.io now has a hard limit of 100 posts returned per API hit, so I'm setting this 100 limit here and will loop through this call until I hit n posts\n",
    "        #get now in epoch date time format\n",
    "        today = datetime.now()\n",
    "        now = today.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        epoch = int(now.timestamp()) #get now in epoch date time format\n",
    "\n",
    "        params = {\n",
    "            'subreddit' : subreddit,\n",
    "            'size' : 100, #pull 100 posts at a time\n",
    "            'before' : epoch #set to now\n",
    "        }\n",
    "        posts = []\n",
    "        # until I have as many posts as called for\n",
    "        while len(posts) <  n:\n",
    "            # get the posts\n",
    "            res = requests.get(url, params)\n",
    "            # convert to list\n",
    "            data = res.json()\n",
    "            # add to list\n",
    "            print(data['data'][99]['created_utc'])\n",
    "            posts.extend(data['data'])\n",
    "            print(len(posts))\n",
    "            # set params 'before' to oldest post's utc\n",
    "            params['before'] = data['data'][99]['created_utc']\n",
    "            # pause for 5 seconds so we're not hitting the API too fast and maxing it out.\n",
    "            time.sleep(5)\n",
    "\n",
    "    return pd.DataFrame(posts) # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 gather 1_000 posts and titles from each of 2 subreddits\n",
    "        - r/bestoflegaladvice\n",
    "        - r/legaladvice\n",
    "\n",
    "NOTE: starting with 1,000 of each, will revist later if it's looking like we need more data.\n",
    "NOTE2: Increased call to 5000 of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594010486\n",
      "100\n",
      "1592482797\n",
      "200\n",
      "1591304165\n",
      "300\n",
      "1590281738\n",
      "400\n",
      "1589406545\n",
      "500\n",
      "1588262292\n",
      "600\n",
      "1587156358\n",
      "700\n",
      "1586049803\n",
      "800\n",
      "1585659170\n",
      "900\n",
      "1584522247\n",
      "1000\n",
      "1583448396\n",
      "1100\n",
      "1582724865\n",
      "1200\n",
      "1581809060\n",
      "1300\n",
      "1581054492\n",
      "1400\n",
      "1580286038\n",
      "1500\n",
      "1579365255\n",
      "1600\n",
      "1578518076\n",
      "1700\n",
      "1577854171\n",
      "1800\n",
      "1577217411\n",
      "1900\n",
      "1576568363\n",
      "2000\n",
      "1575812212\n",
      "2100\n",
      "1574901864\n",
      "2200\n",
      "1574123219\n",
      "2300\n",
      "1573266252\n",
      "2400\n",
      "1572363297\n",
      "2500\n",
      "1571211780\n",
      "2600\n",
      "1570404554\n",
      "2700\n",
      "1569526292\n",
      "2800\n",
      "1568723513\n",
      "2900\n",
      "1567706207\n",
      "3000\n",
      "1566789161\n",
      "3100\n",
      "1565849695\n",
      "3200\n",
      "1565009333\n",
      "3300\n",
      "1564114306\n",
      "3400\n",
      "1563375873\n",
      "3500\n",
      "1562637320\n",
      "3600\n",
      "1561705837\n",
      "3700\n",
      "1561130359\n",
      "3800\n",
      "1560561386\n",
      "3900\n",
      "1559911840\n",
      "4000\n",
      "1559089487\n",
      "4100\n",
      "1558233213\n",
      "4200\n",
      "1557496183\n",
      "4300\n",
      "1556931968\n",
      "4400\n",
      "1556280887\n",
      "4500\n",
      "1555523245\n",
      "4600\n",
      "1554854692\n",
      "4700\n",
      "1554379003\n",
      "4800\n",
      "1553864374\n",
      "4900\n",
      "1553255503\n",
      "5000\n",
      "r/bestoflegaladvice complete\n"
     ]
    }
   ],
   "source": [
    "bola_df = get_posts('bestoflegaladvice', 5_000)\n",
    "print('r/bestoflegaladvice complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595092520\n",
      "100\n",
      "1595077135\n",
      "200\n",
      "1595049873\n",
      "300\n",
      "1595038261\n",
      "400\n",
      "1595028793\n",
      "500\n",
      "1595019983\n",
      "600\n",
      "1595012757\n",
      "700\n",
      "1595006539\n",
      "800\n",
      "1594997823\n",
      "900\n",
      "1594976108\n",
      "1000\n",
      "1594959485\n",
      "1100\n",
      "1594951098\n",
      "1200\n",
      "1594942471\n",
      "1300\n",
      "1594934997\n",
      "1400\n",
      "1594928398\n",
      "1500\n",
      "1594921790\n",
      "1600\n",
      "1594913881\n",
      "1700\n",
      "1594900515\n",
      "1800\n",
      "1594875256\n",
      "1900\n",
      "1594866981\n",
      "2000\n",
      "1594859666\n",
      "2100\n",
      "1594852141\n",
      "2200\n",
      "1594844690\n",
      "2300\n",
      "1594837682\n",
      "2400\n",
      "1594830874\n",
      "2500\n",
      "1594823477\n",
      "2600\n",
      "1594800572\n",
      "2700\n",
      "1594784847\n",
      "2800\n",
      "1594777108\n",
      "2900\n",
      "1594769995\n",
      "3000\n",
      "1594763195\n",
      "3100\n",
      "1594756908\n",
      "3200\n",
      "1594751259\n",
      "3300\n",
      "1594743020\n",
      "3400\n",
      "1594732328\n",
      "3500\n",
      "1594707774\n",
      "3600\n",
      "1594695114\n",
      "3700\n",
      "1594688751\n",
      "3800\n",
      "1594681713\n",
      "3900\n",
      "1594675089\n",
      "4000\n",
      "1594668568\n",
      "4100\n",
      "1594661848\n",
      "4200\n",
      "1594655941\n",
      "4300\n",
      "1594643829\n",
      "4400\n",
      "1594619664\n",
      "4500\n",
      "1594607468\n",
      "4600\n",
      "1594597545\n",
      "4700\n",
      "1594588136\n",
      "4800\n",
      "1594578294\n",
      "4900\n",
      "1594567373\n",
      "5000\n",
      "r/legaladvice complete\n"
     ]
    }
   ],
   "source": [
    "la_df = get_posts('legaladvice', 5_000)\n",
    "print('r/legaladvice complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htlkyk</td>\n",
       "      <td>STOP!!! READ PLEASE!! 💯 Help officers save liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>htfxe1</td>\n",
       "      <td>LAOP's friend is picked up secret-police style...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ht9n1z</td>\n",
       "      <td>LAOP is being harassed by someone claiming to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ht6jc5</td>\n",
       "      <td>LAUKOP is on a maverick weed vigilante quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ht41gd</td>\n",
       "      <td>I dont understand my mom sold me and two of my...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title\n",
       "0  htlkyk  STOP!!! READ PLEASE!! 💯 Help officers save liv...\n",
       "1  htfxe1  LAOP's friend is picked up secret-police style...\n",
       "2  ht9n1z  LAOP is being harassed by someone claiming to ...\n",
       "3  ht6jc5       LAUKOP is on a maverick weed vigilante quest\n",
       "4  ht41gd  I dont understand my mom sold me and two of my..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bola_df[['id', 'title']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the Best of Legal Advice data returned lists 'selftext' as 'deleted'.  That's okay for this iteration as we're only looking at titles to predict the class.\n",
    "\n",
    "This might be something to revist later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>htnf9d</td>\n",
       "      <td>I just bought a car from a private party and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>htner0</td>\n",
       "      <td>My mom is still collecting child support for m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>htneb3</td>\n",
       "      <td>Certification Lost in the Mail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>htncsy</td>\n",
       "      <td>Graffiti w/ Washable Chalk Spray Paint?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>htnc9d</td>\n",
       "      <td>My soon-to-be fiancé's ex raped and impregnate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title\n",
       "0  htnf9d  I just bought a car from a private party and c...\n",
       "1  htner0  My mom is still collecting child support for m...\n",
       "2  htneb3                     Certification Lost in the Mail\n",
       "3  htncsy            Graffiti w/ Washable Chalk Spray Paint?\n",
       "4  htnc9d  My soon-to-be fiancé's ex raped and impregnate..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la_df[['id', 'title']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STOP!!! READ PLEASE!! 💯 Help officers save liv...</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAOP's friend is picked up secret-police style...</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LAOP is being harassed by someone claiming to ...</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAUKOP is on a maverick weed vigilante quest</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I dont understand my mom sold me and two of my...</td>\n",
       "      <td>bestoflegaladvice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title          subreddit\n",
       "0  STOP!!! READ PLEASE!! 💯 Help officers save liv...  bestoflegaladvice\n",
       "1  LAOP's friend is picked up secret-police style...  bestoflegaladvice\n",
       "2  LAOP is being harassed by someone claiming to ...  bestoflegaladvice\n",
       "3       LAUKOP is on a maverick weed vigilante quest  bestoflegaladvice\n",
       "4  I dont understand my mom sold me and two of my...  bestoflegaladvice"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bola_df[['title', 'subreddit']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to save my bulk file first so I don't have to re-hit the pushshift API again until I decide I want more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_df = pd.concat([bola_df, la_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_df.to_csv('./data/bulkredditdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment, this is what I'm looking for, the two dataframes are compatible and getting the data I'm looking for.  Time to filter and save to .csv as clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Cleaning\n",
    "\n",
    "In this particular case, I have no nans but I have a lot more columns than I am currently examining.  \n",
    "\n",
    "For this version of the project, all I am looking at is titles and which subreddit it belongs to.  I'll slice it to the two relevant columns and save it as clean_reddit_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_bola_df = bola_df[['title', 'subreddit']].copy()\n",
    "clean_la_df = la_df[['title', 'subreddit']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.concat([clean_bola_df, clean_la_df], ignore_index = True)\n",
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 save data to CSV for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('./data/clean_reddit_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All set!  Moving over to modeling for EDA and modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit (conda)",
   "language": "python",
   "name": "python37764bitconda77dc9d652bc147c6a9d0ea8af6b5ba0e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
